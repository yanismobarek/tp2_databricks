Metadata-Version: 2.1
Name: sales-pipeline-spark
Version: 0.1.0
Summary: Pipeline ETL Spark pour l'analyse des ventes.
Keywords: spark,pyspark,etl,databricks
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: pyyaml>=6.0
Requires-Dist: pytest>=7.0

# Sales Pipeline Project

## ğŸ“Œ But du projet
Ce projet implÃ©mente un **pipeline ETL** pour les ventes de boutiques Ã  Paris.  
Le pipeline suit les Ã©tapes classiques **Bronze â†’ Silver â†’ Gold** :

- **Bronze** : ingestion des fichiers CSV bruts dans une table Delta.  
- **Silver** : nettoyage et standardisation des donnÃ©es (suppression des valeurs nulles, types corrects, etc.).  
- **Gold** : agrÃ©gation et calcul des indicateurs clÃ©s (ex : ventes par produit, chiffre dâ€™affaires total).  

---

## âš™ï¸ Comment exÃ©cuter le pipeline

1. Assurez-vous dâ€™avoir un environnement Python avec les dÃ©pendances du projet :  

```
pip install -r requirements.txt```

Lancez le pipeline principal :

```
python main.py```

Le pipeline va exÃ©cuter les Ã©tapes dans lâ€™ordre :

Ingestion (Bronze)

Nettoyage (Silver)

AgrÃ©gation (Gold)

Les rÃ©sultats Gold seront affichÃ©s dans la console et sauvegardÃ©s dans des tables Delta
